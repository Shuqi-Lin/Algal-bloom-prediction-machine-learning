{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developed-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import random\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', 100)  # or 1000\n",
    "pd.set_option('display.max_rows', 100)  # or 1000\n",
    "import shap\n",
    "import time\n",
    "from numpy import concatenate\n",
    "Scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-screw",
   "metadata": {},
   "source": [
    "# Load training datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "centered-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..\\\\Algal-bloom-prediction-machine-learning\\\\Trainning data')\n",
    "all_df = pd.read_csv('Observation_df.csv',sep = ',')\n",
    "all_df['Date'] = pd.to_datetime(all_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "agricultural-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(all_df,sample_interval):\n",
    "    drop_row = []\n",
    "    dT = 0\n",
    "    i = 1\n",
    "    sample_df = all_df.copy()\n",
    "\n",
    "    while True:\n",
    "        dT = (sample_df['Date'].iloc[i]-sample_df['Date'].iloc[i-1])/np.timedelta64(1, 'D')\n",
    "        if dT<sample_interval: # set the data frequency (over 10, 14, 20 days)\n",
    "            #print(sample_df['Date'].iloc[i])\n",
    "            sample_df.drop(sample_df.index.values[i],axis = 0,inplace  =True)\n",
    "        else:\n",
    "            i+=1\n",
    "        if i>=len(sample_df):break\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "obvious-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing dataset(Daily data)\n",
    "def read_daily_df(test_yr,features,file):\n",
    "    Erken_HydMet = pd.read_csv(file,header = 0)\n",
    "    Erken_HydMet['Date'] = pd.to_datetime(Erken_HydMet['Date'])\n",
    "    Erken_HydMet['year'] = Erken_HydMet['Date'].apply(lambda y:y.year)\n",
    "    Erken_HydMet = Erken_HydMet[Erken_HydMet['year']==test_yr]\n",
    "    return Erken_HydMet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tough-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_cv(df,features,nutrient,year):\n",
    "    df = df[df['YY'].isin(year)]\n",
    "    X_train = df[features]\n",
    "    y_train = df[nutrient].values\n",
    "\n",
    "    GBR = GradientBoostingRegressor(random_state=101)\n",
    "    n_estimators = [int(x) for x in np.arange(40,140,20)]\n",
    "    max_depth=[int(x) for x in np.arange(5,10,1)]\n",
    "    learning_rate = [x for x in [0.01,0.1,1]]\n",
    "    subsample = [x for x in [0.7,0.8,0.9,1]]\n",
    "    param_grid = {'n_estimators': n_estimators,\n",
    "                  'max_depth': max_depth,\n",
    "                  'learning_rate':learning_rate,\n",
    "                  'subsample':subsample}\n",
    "    GBR_rs = RandomizedSearchCV(estimator = GBR,param_distributions = param_grid,n_iter = 30,cv = 10,verbose = 0)\n",
    "    GBR_rs.fit(X_train,y_train)\n",
    "    GBR.set_params(**GBR_rs.best_params_,random_state=101).fit(X_train,y_train)\n",
    "    #rmse = -cross_val_score(GBR, X_train, y_train, cv=5,scoring = 'neg_root_mean_squared_error')\n",
    "    #r2 = cross_val_score(GBR, X_train, y_train, cv=5,scoring = 'r2')\n",
    "    #print('Training dataset evaluation:')\n",
    "    #print(\"RMSE %.2f (+/- %.2f)\" % (rmse.mean(), rmse.std()))\n",
    "    #print(\"R2 %.2f (+/- %0.2f)\" % (r2.mean(), r2.std()))\n",
    "    pickle.dump(GBR, open(\"GBR.\"+nutrient.split('(')[0]+\".dat\", \"wb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "virgin-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Erken_Nut,df,features,nutrient,RMSE,R2):\n",
    "    #load the target GBR model\n",
    "    GBR = pickle.load(open(\"GBR.\"+nutrient.split('(')[0]+\".dat\", \"rb\"))\n",
    "    #predict yhat using test_X\n",
    "    Erken_Nut[nutrient]=GBR.predict(Erken_Nut[features])\n",
    "    nutrient_compare = Erken_Nut[['Date',nutrient]].merge(df[['Date',nutrient]],\n",
    "                                                          how = 'inner',on = 'Date')\n",
    "    nutrient_compare.columns = ['Date','Prediction','True']\n",
    "    Date = pd.DataFrame(pd.date_range(start = pd.Timestamp(2017,1,1),\n",
    "                                  end = pd.Timestamp(2021,1,1)),\n",
    "                    columns = ['Date'])\n",
    "    Erken_Nut_gap = Date.merge(Erken_Nut,how = 'left',on = 'Date')\n",
    "\n",
    "    RMSE.append(mean_squared_error(nutrient_compare['True'],nutrient_compare['Prediction'],squared = False))    \n",
    "    R2.append(r2_score(nutrient_compare['True'],nutrient_compare['Prediction']))\n",
    "    return Erken_Nut[['Date',nutrient]],RMSE,R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ethical-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the dataset \n",
    "sample_df = resample(all_df,21)\n",
    "# Specify the features used to make prediction\n",
    "features = ['Date','month','U','SST','AirT','delT','Humidity','CC','swr(w/m2)','Prec(mm/d)','inflow(m3/s)',\n",
    "           'Ice_d','days from iceoff','MLD','thermD','W']\n",
    "year = list(range(2004,2021))\n",
    "\n",
    "Erken_NOX = pd.DataFrame(columns = ['Date','NOX(mmole/m3)'])\n",
    "Erken_O2 = pd.DataFrame(columns = ['Date','O2(mmole/m3)'])\n",
    "Erken_NH4 = pd.DataFrame(columns = ['Date','NH4(mmole/m3)'])\n",
    "Erken_PO4 = pd.DataFrame(columns = ['Date','PO4(mmole/m3)'])\n",
    "Erken_TP = pd.DataFrame(columns = ['Date','TP(mmole/m3)'])\n",
    "Erken_Si = pd.DataFrame(columns = ['Date','Si(mmole/m3)'])\n",
    "Erken_Chl = pd.DataFrame(columns = ['Date','Chl(mg/m3)'])\n",
    "\n",
    "NOX_RMSE = []\n",
    "NOX_R2 = []\n",
    "O2_RMSE = []\n",
    "O2_R2 = []\n",
    "NH4_RMSE = []\n",
    "NH4_R2 = []\n",
    "PO4_RMSE = []\n",
    "PO4_R2 = []\n",
    "TP_RMSE = []\n",
    "TP_R2 = []\n",
    "Si_RMSE = []\n",
    "Si_R2 = []\n",
    "Chl_RMSE = []\n",
    "Chl_R2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "square-facility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n",
      "Model takes 2 min to run\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(year)):\n",
    "    start_time = time.time()\n",
    "    # Specify the training and testing years\n",
    "    test_yr = year[i]\n",
    "    training_yr = year.copy()\n",
    "    training_yr.remove(test_yr)\n",
    "\n",
    "    # Load the testing daily df\n",
    "    file = 'Daily_Observation_df.csv'\n",
    "    testing_daily_df = read_daily_df(test_yr,features,file) \n",
    "    \n",
    "    os.chdir('..\\Sample sparsity test\\GBR')\n",
    "    ## Predict NOX\n",
    "    features = ['inflow(m3/s)','AirT','Prec(mm/d)','delT','U','Humidity','CC','swr(w/m2)','Ice_d','days from iceoff',\n",
    "                'MLD','W','thermD']\n",
    "    model = training_cv(sample_df,features,'NOX(mmole/m3)',training_yr)\n",
    "    NOX_Model,NOX_RMSE,NOX_R2 = predict(testing_daily_df,all_df,features,'NOX(mmole/m3)',NOX_RMSE,NOX_R2)\n",
    "    Erken_NOX = pd.concat([Erken_NOX,NOX_Model])\n",
    "    #Erken_Nut = testing_daily_df.merge(NOX_Model,on = 'Date',how = 'left')\n",
    "    \n",
    "    ## Predict O2\n",
    "    features = ['inflow(m3/s)','AirT','Prec(mm/d)','delT','U','Humidity','CC','swr(w/m2)','Ice_d','days from iceoff',\n",
    "                'MLD','W','thermD']\n",
    "    model = training_cv(sample_df,features,'O2(mmole/m3)',training_yr)\n",
    "    O2_Model,O2_RMSE,O2_R2 = predict(testing_daily_df,all_df,features,'O2(mmole/m3)',O2_RMSE,O2_R2)\n",
    "    Erken_O2 = pd.concat([Erken_O2,O2_Model])\n",
    "    #Erken_Nut = Erken_Nut.merge(O2_Model,on = 'Date',how = 'left')\n",
    "    \n",
    "    ## Predict NH4\n",
    "    features = ['inflow(m3/s)','AirT','Prec(mm/d)','delT','U','Humidity','CC','swr(w/m2)','Ice_d','days from iceoff',\n",
    "                'MLD','W','thermD','NOX(mmole/m3)','O2(mmole/m3)']\n",
    "    model = training_cv(sample_df,features,'NH4(mmole/m3)',training_yr)\n",
    "    NH4_Model,NH4_RMSE,NH4_R2 = predict(testing_daily_df,all_df,features,'NH4(mmole/m3)',NH4_RMSE,NH4_R2)\n",
    "    Erken_NH4 = pd.concat([Erken_NH4,NH4_Model])\n",
    "    #Erken_Nut = Erken_Nut.merge(NH4_Model,on = 'Date',how = 'left')\n",
    "    \n",
    "    ## Predict PO4\n",
    "    features = ['inflow(m3/s)','AirT','Prec(mm/d)','delT','U','Humidity','CC','swr(w/m2)','Ice_d','days from iceoff',\n",
    "                'MLD','W','thermD','NOX(mmole/m3)','O2(mmole/m3)']\n",
    "    model = training_cv(sample_df,features,'PO4(mmole/m3)',training_yr)\n",
    "    PO4_Model,PO4_RMSE,PO4_R2 = predict(testing_daily_df,all_df,features,'PO4(mmole/m3)',PO4_RMSE,PO4_R2)\n",
    "    Erken_PO4 = pd.concat([Erken_PO4,PO4_Model])\n",
    "    #Erken_Nut = Erken_Nut.merge(PO4_Model,on = 'Date',how = 'left')\n",
    "    \n",
    "    ## Predict TP\n",
    "    features = ['inflow(m3/s)','AirT','Prec(mm/d)','delT','Ice_d','days from iceoff','U','Humidity','CC','swr(w/m2)',\n",
    "                'MLD','W','thermD','NOX(mmole/m3)','PO4(mmole/m3)','O2(mmole/m3)']\n",
    "    model = training_cv(sample_df,features,'TotP(mmole/m3)',training_yr)\n",
    "    TP_Model,TP_RMSE,TP_R2 = predict(testing_daily_df,all_df,features,'TotP(mmole/m3)',TP_RMSE,TP_R2)\n",
    "    Erken_TP = pd.concat([Erken_TP,TP_Model])\n",
    "    #Erken_Nut = Erken_Nut.merge(TP_Model,on = 'Date',how = 'left')\n",
    "\n",
    "    ## Predict Si\n",
    "    features = ['inflow(m3/s)','AirT','Prec(mm/d)','delT','Ice_d','days from iceoff','U','Humidity','CC','swr(w/m2)',\n",
    "                'MLD','W','thermD','NOX(mmole/m3)','PO4(mmole/m3)','O2(mmole/m3)']\n",
    "    model = training_cv(sample_df,features,'Si(mmole/m3)',training_yr)\n",
    "    Si_Model,Si_RMSE,Si_R2 = predict(testing_daily_df,all_df,features,'Si(mmole/m3)',Si_RMSE,Si_R2)\n",
    "    Erken_Si = pd.concat([Erken_Si,Si_Model])\n",
    "    #Erken_Nut = Erken_Nut.merge(Si_Model,on = 'Date',how = 'left')\n",
    "    \n",
    "    ## Predict Chl via the same GBR method as the one used to pre-generate nutrients\n",
    "    features = ['inflow(m3/s)','AirT','Prec(mm/d)','delT','Ice_d','days from iceoff','U','Humidity','CC','swr(w/m2)',\n",
    "                'MLD','W','thermD',\n",
    "                'NOX(mmole/m3)','PO4(mmole/m3)','Si(mmole/m3)', 'TotP(mmole/m3)','NH4(mmole/m3)','O2(mmole/m3)']\n",
    "    model = training_cv(sample_df,features,'Chl(mg/m3)',training_yr)\n",
    "    Chl_Model,Chl_RMSE,Chl_R2 = predict(testing_daily_df,all_df,features,'Chl(mg/m3)',Chl_RMSE,Chl_R2)\n",
    "    Erken_Chl = pd.concat([Erken_Chl,Chl_Model])\n",
    "    #Erken_Nut = Erken_Nut.merge(Chl_Model,on = 'Date',how = 'left')\n",
    "\n",
    "    print('Model takes '+str(round((time.time()-start_time)/60))+' min to run')\n",
    "    os.chdir('../..')\n",
    "    os.chdir('..\\\\Algal-bloom-prediction-machine-learning\\\\Trainning data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-robert",
   "metadata": {},
   "source": [
    "# Output predicted values and evaluating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "surgical-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..\\Sample sparsity test\\GBR')\n",
    "Erken_Nut = Erken_NOX.merge(Erken_NH4,\n",
    "                on='Date',\n",
    "                how = 'left').merge(Erken_O2,\n",
    "                                    on='Date',\n",
    "                                    how = 'left').merge(Erken_PO4,\n",
    "                                                        on='Date',\n",
    "                                                        how = 'left').merge(Erken_TP,\n",
    "                                                                            on = 'Date',\n",
    "                                                                            how='left').merge(Erken_Si,\n",
    "                                                                                              on='Date',\n",
    "                                                                                              how = 'left').merge(Erken_Chl,\n",
    "                                                                                                                  on='Date',\n",
    "                                                                                                                  how = 'left')\n",
    "Erken_Nut.drop('TP(mmole/m3)',axis = 1,inplace = True)\n",
    "Erken_Nut.to_csv('GBR predicted nutrient_predicted nutrient and Chl.csv',index = False)\n",
    "\n",
    "RMSE = pd.DataFrame({'NOX':NOX_RMSE,'NH4':NH4_RMSE,'O2':O2_RMSE,'PO4':PO4_RMSE,'TP':TP_RMSE,'Si':Si_RMSE,'Chl':Chl_RMSE},index = year)\n",
    "RMSE.to_csv('RMSE.csv',index = False)\n",
    "\n",
    "R2 = pd.DataFrame({'NOX':NOX_R2,'NH4':NH4_R2,'O2':O2_R2,'PO4':PO4_R2,'TP':TP_R2,'Si':Si_R2,'Chl':Chl_R2},index = year)\n",
    "R2.to_csv('R2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "hollywood-booking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
